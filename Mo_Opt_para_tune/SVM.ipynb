{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8523 entries, 0 to 8522\n",
      "Data columns (total 39 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Item_Weight                      8523 non-null   float64\n",
      " 1   Item_MRP                         8523 non-null   float64\n",
      " 2   Item_Type_Baking Goods           8523 non-null   uint8  \n",
      " 3   Item_Type_Breads                 8523 non-null   uint8  \n",
      " 4   Item_Type_Breakfast              8523 non-null   uint8  \n",
      " 5   Item_Type_Canned                 8523 non-null   uint8  \n",
      " 6   Item_Type_Dairy                  8523 non-null   uint8  \n",
      " 7   Item_Type_Frozen Foods           8523 non-null   uint8  \n",
      " 8   Item_Type_Fruits and Vegetables  8523 non-null   uint8  \n",
      " 9   Item_Type_Hard Drinks            8523 non-null   uint8  \n",
      " 10  Item_Type_Health and Hygiene     8523 non-null   uint8  \n",
      " 11  Item_Type_Household              8523 non-null   uint8  \n",
      " 12  Item_Type_Meat                   8523 non-null   uint8  \n",
      " 13  Item_Type_Others                 8523 non-null   uint8  \n",
      " 14  Item_Type_Seafood                8523 non-null   uint8  \n",
      " 15  Item_Type_Snack Foods            8523 non-null   uint8  \n",
      " 16  Item_Type_Soft Drinks            8523 non-null   uint8  \n",
      " 17  Item_Type_Starchy Foods          8523 non-null   uint8  \n",
      " 18  Item_Fat_Content_Low Fat         8523 non-null   uint8  \n",
      " 19  Item_Fat_Content_Regular         8523 non-null   uint8  \n",
      " 20  Outlet_Type_Grocery Store        8523 non-null   uint8  \n",
      " 21  Outlet_Type_Supermarket Type1    8523 non-null   uint8  \n",
      " 22  Outlet_Type_Supermarket Type2    8523 non-null   uint8  \n",
      " 23  Outlet_Type_Supermarket Type3    8523 non-null   uint8  \n",
      " 24  Outlet_Location_Type_Tier 1      8523 non-null   uint8  \n",
      " 25  Outlet_Location_Type_Tier 2      8523 non-null   uint8  \n",
      " 26  Outlet_Location_Type_Tier 3      8523 non-null   uint8  \n",
      " 27  Outlet_Size_High                 8523 non-null   uint8  \n",
      " 28  Outlet_Size_Medium               8523 non-null   uint8  \n",
      " 29  Outlet_Size_Small                8523 non-null   uint8  \n",
      " 30  Outlet_Establishment_Year_1985   8523 non-null   uint8  \n",
      " 31  Outlet_Establishment_Year_1987   8523 non-null   uint8  \n",
      " 32  Outlet_Establishment_Year_1997   8523 non-null   uint8  \n",
      " 33  Outlet_Establishment_Year_1998   8523 non-null   uint8  \n",
      " 34  Outlet_Establishment_Year_1999   8523 non-null   uint8  \n",
      " 35  Outlet_Establishment_Year_2002   8523 non-null   uint8  \n",
      " 36  Outlet_Establishment_Year_2004   8523 non-null   uint8  \n",
      " 37  Outlet_Establishment_Year_2007   8523 non-null   uint8  \n",
      " 38  Outlet_Establishment_Year_2009   8523 non-null   uint8  \n",
      "dtypes: float64(2), uint8(37)\n",
      "memory usage: 441.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "sales_predict_df = pd.read_csv(\"../Alex's Model/Resources/Train_Output_CSV.csv\")\n",
    "\n",
    "# Prepare features and target\n",
    "# Drop the target column \"Item_Outlet_Sales\" from the feature DataFrame\n",
    "features_df = sales_predict_df.drop(columns=['Item_Outlet_Sales','Item_Identifier','Outlet_Identifier','Item_Visibility'])\n",
    "\n",
    "features_df = pd.get_dummies(features_df, columns=['Item_Type',\"Item_Fat_Content\",\"Outlet_Type\" ,'Outlet_Location_Type','Outlet_Size' ,'Outlet_Establishment_Year' ])\n",
    "\n",
    "# Extract target variables\n",
    "target_df = sales_predict_df['Item_Outlet_Sales']\n",
    "features_df.info()\n",
    "\n",
    "X = features_df.values\n",
    "y = target_df.values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define parameter distributions for random search\n",
    "param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'epsilon': [0.01, 0.1, 0.2, 0.3],  # Epsilon for epsilon-insensitive loss\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n",
    "    'degree': [2, 3, 4]  # Degree for polynomial kernel\n",
    "}\n",
    "\n",
    "# Create SVM model\n",
    "svm_regressor = SVR()\n",
    "\n",
    "# Create randomized search object\n",
    "random_search = RandomizedSearchCV(estimator=svm_regressor, param_distributions=param_dist, n_iter=40, scoring='r2', cv=5)\n",
    "\n",
    "# Fit randomized search to the data\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = random_search.best_params_\n",
    "best_r2 = random_search.best_score_\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best R^2 Score: \", best_r2)\n",
    "\n",
    "# Train the model using the best parameters\n",
    "svm_regressor = SVR(**best_params)\n",
    "svm_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = svm_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# # Define the hyperparameter grid for Randomized Search\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300, 900],\n",
    "#     'max_depth': [10, 20, 30, 200],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 3, 9],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Create a RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=RandomForestRegressor(random_state=3),\n",
    "#     param_distributions=param_grid,\n",
    "#     n_iter=30,\n",
    "#     scoring='r2',\n",
    "#     cv=5,\n",
    "#     random_state=3,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit the RandomizedSearchCV on the training data\n",
    "# random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# # Get the best model from RandomizedSearchCV\n",
    "# best_regressor = random_search.best_estimator_\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# sales_data_predictions = best_regressor.predict(X_test_scaled)\n",
    "\n",
    "# # Calculate R squared value\n",
    "# r2_sales = metrics.r2_score(y_test, sales_data_predictions)\n",
    "# print('R Squared value =', r2_sales)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

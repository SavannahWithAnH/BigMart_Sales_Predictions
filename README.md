# BigMart Sales Data Neural Network

**Topic:** Create a model which predicts sales of products at BigMart locations based on 2013 Sales data. 
Click [here](https://docs.google.com/presentation/d/1MLGNz3lZow-65TH0pca2mxmcsVfNuM0Paq-pxnvl1vI/edit#slide=id.g278fa82c89e_0_50) to view our findings presentation.
  
## Project Proposal



# Contributors & Responsibilities
- Alex Kopp - TBD
- Andrew Skorupa - TBD 
- Savannah Porter - Random Forest, Randomized Search, & Regularization
- Mohamed Abou elkhier -  TBD
 
## Datasets
Click [here](https://www.kaggle.com/code/hiralmshah/bigmart-sales-prediction/notebook) to view one of our primary datasets!

Item_Identifier: Unique product ID

Item_Weight: Weight of product

Item_Fat_Content: Whether the product is low fat or not

Item_Visibility: The % of total display area of all products in a store allocated to the particular product

Item_Type: The category to which the product belongs

Item_MRP: Maximum Retail Price (list price) of the product

Outlet_Identifier: Unique store ID

Outlet_Establishment_Year: The year in which store was established

Outlet_Size: The size of the store in terms of ground area covered

Outlet_Location_Type: The type of city in which the store is located

Outlet_Type: Whether the outlet is just a grocery store or some sort of supermarket

Item_Outlet_Sales: Sales of the product in the particulat store. This is the outcome variable to be predicted.
## Project Deliverables
Our project will provide analysis of the following areas:
- Accurate model for predicting 2014 Sales of product by product and location
- Provide comparative data for projectied sales across locations
- Provide aggregate for total sales predicted in 2014.


# Data collection, cleaning, modeling, and visualization tools
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and Analysis


    - Entity Relationship Diagram was also created using pgAdmin4 and saved as "ERD.png" to represent the visual of the relationship between our two data set 
    <img width="500" alt="image" src="./SQL/ERD.png">


# Part 1: Database and table setup
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis

# Part 2: Data validation and exploration
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis

# Part 3: Model Creation
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis

# Part 4: Model Training
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis

# Part 5: Model Testing
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis

# Part 6: Model Optimization
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis

# Part 7: Data Output Visualization and Analysis
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and Analysis

# Data collection, cleaning, modeling, and visualization tools
- SQL for database and table setup, data validation, exploration, and analysis. we divided to 3 parts
    - PART 1: Datebase and table setup
    - PART 2: Data validation and exploration
    - PART 3: Model Creation
    - PART 4: Model Training
    - PART 5: Model Testing
    - PART 6: Model Optimization
    - PART 7: Data Output Visualization and analysis


- Python and panda to clean and convert csv files to json.



- Plotly for interactive bar and line graphs visualizing stock price changes over time. 

- Flask app using 'render_template' to serve up the dashboard and jsonify to pull in data files enabling dashboard. please check 'Memo' in our application.py for more info.


**Please visit our individual Github pages below**  
[Alex Kopp](https://github.com/alexkopp12)  
[Andrew Skorupa](https://github.com/AndyMSkor)  
[Savannah Porter](https://github.com/SavannahWithAnH)  
[Mohamed Abou elkhier](https://github.com/nabroo101)  
 
